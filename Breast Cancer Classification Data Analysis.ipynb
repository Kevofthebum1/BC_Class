{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58b96b2",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7206e",
   "metadata": {},
   "source": [
    "For this notebook, we want to predict whether the breast cancer is either malignant or benign using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b2cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c6c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the variable for our dataset\n",
    "breast_cancer = pd.read_csv(\"C:\\\\Users\\\\Kevin Luu\\\\Downloads\\\\breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c6270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking for info of the data\n",
    "display(breast_cancer.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2915b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#basic stats of the dataset\n",
    "display(breast_cancer.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d187765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         False\n",
       "diagnosis                  False\n",
       "radius_mean                False\n",
       "texture_mean               False\n",
       "perimeter_mean             False\n",
       "area_mean                  False\n",
       "smoothness_mean            False\n",
       "compactness_mean           False\n",
       "concavity_mean             False\n",
       "concave points_mean        False\n",
       "symmetry_mean              False\n",
       "fractal_dimension_mean     False\n",
       "radius_se                  False\n",
       "texture_se                 False\n",
       "perimeter_se               False\n",
       "area_se                    False\n",
       "smoothness_se              False\n",
       "compactness_se             False\n",
       "concavity_se               False\n",
       "concave points_se          False\n",
       "symmetry_se                False\n",
       "fractal_dimension_se       False\n",
       "radius_worst               False\n",
       "texture_worst              False\n",
       "perimeter_worst            False\n",
       "area_worst                 False\n",
       "smoothness_worst           False\n",
       "compactness_worst          False\n",
       "concavity_worst            False\n",
       "concave points_worst       False\n",
       "symmetry_worst             False\n",
       "fractal_dimension_worst    False\n",
       "Unnamed: 32                 True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking for any null values in the dataset\n",
    "display(breast_cancer.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bafa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "#deleting the null value and id column\n",
    "breast_cancer.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbfbd27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if the column is deleted\n",
    "breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae584dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer['diagnosis'] = breast_cancer['diagnosis'].apply(lambda x: 1 if x=='M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a5d924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if diagnosis in the dataset has values 0, and 1\n",
    "breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7f8125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    int64  \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986756f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the values in the diagnosis column in the dataset\n",
    "diagnosis_count = breast_cancer['diagnosis'].value_counts()\n",
    "display(diagnosis_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5408b7",
   "metadata": {},
   "source": [
    "# Statistical Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba046b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plottng the distribution of the diagnosis column of the dataset\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=breast_cancer, x='diagnosis')\n",
    "plt.title('The Distribution of diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bcea36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Boxplot of the selected features\n",
    "\n",
    "selected_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(data=breast_cancer[selected_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ccd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the independent and dependent variables\n",
    "\n",
    "X = breast_cancer.drop(['diagnosis'], axis=1)\n",
    "Y = breast_cancer['diagnosis'] #What we are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc222b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing a train test split for the independent and dependent varaible\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing statistical packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00267298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9298245614035088\n",
      "The accuracy score for the training set: 0.945054945054945\n",
      "The confusion matrix for the test set:\n",
      " [[70  5]\n",
      " [ 3 36]]\n",
      "The classification report for the test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        75\n",
      "           1       0.88      0.92      0.90        39\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.93      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the training set:\", accuracy_score(y_train, lr.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classification report for the test set:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36de7b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20],\n",
       "                         'gamma': [0.0001, 0.001, 0.01, 0.1]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Classifier (SVC)\n",
    "svc = SVC()\n",
    "\n",
    "parameters = {\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svc, parameters)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac9c192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 15, 'gamma': 0.0001}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9472527472527472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Figuring out the best parameters and the score when using SVC\n",
    "display(grid_search.best_params_)\n",
    "display(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec539552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9385964912280702\n",
      "The accuracy score for the training set: 0.9692307692307692\n",
      "The confusion matrix for the test set:\n",
      " [[71  4]\n",
      " [ 3 36]]\n",
      "The classification report for the test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        75\n",
      "           1       0.90      0.92      0.91        39\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using SVC on the train and test set\n",
    "svc = SVC(C = 15, gamma = 0.0001)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the training set:\", accuracy_score(y_train, svc.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classification report for the test set:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b15fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8640 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: range(2, 32),\n",
       "                         &#x27;min_samples_leaf&#x27;: range(1, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(2, 10),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: range(2, 32),\n",
       "                         &#x27;min_samples_leaf&#x27;: range(1, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(2, 10),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(2, 32),\n",
       "                         'min_samples_leaf': range(1, 10),\n",
       "                         'min_samples_split': range(2, 10),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "parameters={\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,32,1),\n",
    "    'min_samples_leaf': range(1,10,1),\n",
    "    'min_samples_split': range(2,10,1),\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "grid_search_dtc = GridSearchCV(dtc, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4245b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 9,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 7,\n",
       " 'splitter': 'random'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9604395604395604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Figuring out the best parameters and score for Decision Tree Classifier\n",
    "display(grid_search_dtc.best_params_)\n",
    "display(grid_search_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f964a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9473684210526315\n",
      "The accuracy score for the traning set: 0.9648351648351648\n",
      "The confusion matrix for the test set:\n",
      " [[73  2]\n",
      " [ 4 35]]\n",
      "The classification report for the test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        75\n",
      "           1       0.95      0.90      0.92        39\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Doing Decision Tree Classifier with our best parameters for the train and test set\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=12, min_samples_leaf=3, min_samples_split=7, splitter='random')\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the traning set:\", accuracy_score(y_train, dtc.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classification report for the test set:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0c712ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9736842105263158\n",
      "The accuracy score for the training set: 0.9868131868131869\n",
      "The confusion matrix for the test set:\n",
      " [[73  2]\n",
      " [ 1 38]]\n",
      "The classification report for the test test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        75\n",
      "           1       0.95      0.97      0.96        39\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "rf = RandomForestClassifier(criterion='gini', max_depth=29, min_samples_leaf=3, min_samples_split=5, max_features='log2', \n",
    "                            n_estimators=130)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the training set:\", accuracy_score(y_train, rf.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classification report for the test test:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf16a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9736842105263158\n",
      "The accuracy score for the training set: 1.0\n",
      "The confusion matrix for the test set:\n",
      " [[73  2]\n",
      " [ 1 38]]\n",
      "The classification report for the test set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        75\n",
      "           1       0.95      0.97      0.96        39\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifier()\n",
    "ada = AdaBoostClassifier(dtc, n_estimators=190)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the training set:\", accuracy_score(y_train, ada.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classification report for the test set\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "706295fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "80 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.61978022 0.61978022\n",
      " 0.61978022 0.61978022        nan        nan        nan        nan\n",
      " 0.95604396 0.96043956 0.96263736 0.96043956        nan        nan\n",
      "        nan        nan 0.96703297 0.96703297 0.96703297 0.96703297\n",
      "        nan        nan        nan        nan 0.88351648 0.87912088\n",
      " 0.88131868 0.87692308]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.001, 0.1, 1, 10],\n",
       "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 150, 180, 200]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.001, 0.1, 1, 10],\n",
       "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 150, 180, 200]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.1, 1, 10],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'n_estimators': [100, 150, 180, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'loss':['deviance', 'exponential'],\n",
    "    'learning_rate':[0.001, 0.1, 1, 10],\n",
    "    'n_estimators':[100, 150, 180, 200]\n",
    "}\n",
    "\n",
    "grid_search_gbc = GridSearchCV(gbc, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66b54c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9670329670329672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#figuring out the best parameter and score for the GradientBoostingClassifier\n",
    "display(grid_search_gbc.best_params_)\n",
    "display(grid_search_gbc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0b07dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the test set: 0.9649122807017544\n",
      "The accuracy score for the training set: 1.0\n",
      "The confusion matrix for the test set:\n",
      " [[72  3]\n",
      " [ 1 38]]\n",
      "The classifiction report for the test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97        75\n",
      "           1       0.93      0.97      0.95        39\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using our printed best parameters for our train and test set\n",
    "gbc = GradientBoostingClassifier(learning_rate=1, loss='exponential', n_estimators=100)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score for the test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"The accuracy score for the training set:\", accuracy_score(y_train, gbc.predict(X_train)))\n",
    "\n",
    "print(\"The confusion matrix for the test set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The classifiction report for the test set:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8770267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "The cancer cell is benign.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Luu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Making our prediction model\n",
    "\n",
    "input_data = (8.196,16.84,51.71,201.9,0.086,0.05943,0.01588,0.005917,0.1769,0.06503,0.1563,0.9567,1.094,8.205,0.008968,0.01646,0.01588,0.005917,0.02574,0.002582,8.964,21.96,57.26,242.2,0.1297,0.1357,0.0688,0.02564,0.3105,0.07409)\n",
    "#changing our variable into a numpy array\n",
    "input_data_into_numpy_array = np.asarray(input_data)\n",
    "\n",
    "#reshaping the numpy array as we are predicting for one datapoint\n",
    "input_data_reshaped = input_data_into_numpy_array.reshape(1,-1)\n",
    "\n",
    "#We will pick logistic regression model out of the other models for our prediction model \n",
    "prediction = lr.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==1):\n",
    "    print(\"The cancer cell is malignant.\")\n",
    "else:\n",
    "    print(\"The cancer cell is benign.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847fb07",
   "metadata": {},
   "source": [
    "**NOTE**: If we want to use KNeighborsClassifier(), we would need to scale our X_train and X_test. This would help make the shape of the dataset become equal. However, scaling the data for KNeighborsClassifier() would result in getting us the wrong prediction for our dataset. When running the prediction model after scaling, the model kept printing [1], but it should be [0] for our input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
